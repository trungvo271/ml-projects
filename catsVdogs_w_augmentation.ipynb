{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "78409a8e",
      "metadata": {
        "id": "78409a8e"
      },
      "source": [
        "## Cats vs Dogs - with simple data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "806713b6",
      "metadata": {
        "id": "806713b6"
      },
      "source": [
        "### Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dn-6c02VmqiN",
      "metadata": {
        "id": "dn-6c02VmqiN",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3789657",
      "metadata": {
        "id": "a3789657"
      },
      "source": [
        "### Download data-set\n",
        "(ref: tensorflow tutorial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3sd9dQWa23aj",
      "metadata": {
        "id": "3sd9dQWa23aj",
        "lines_to_next_cell": 2,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# If the URL doesn't work, visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
        "# And right click on the 'Download Manually' link to get a new URL to the dataset\n",
        "\n",
        "# Note: This is a very large dataset and will take some time to download\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\" \\\n",
        "    -O \"/tmp/cats-and-dogs.zip\"\n",
        "\n",
        "local_zip = '/tmp/cats-and-dogs.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77836d61",
      "metadata": {
        "id": "77836d61"
      },
      "source": [
        "### Sorting data-set into sub-directories for data generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DM851ZmN28J3",
      "metadata": {
        "id": "DM851ZmN28J3",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "source_path = '/tmp/PetImages'\n",
        "\n",
        "source_path_dogs = os.path.join(source_path, 'Dog')\n",
        "source_path_cats = os.path.join(source_path, 'Cat')\n",
        "\n",
        "# Deletes all non-image files (there are two .db files bundled into the dataset)\n",
        "!find /tmp/PetImages/ -type f ! -name \"*.jpg\" -exec rm {} +\n",
        "\n",
        "# os.listdir returns a list containing all files under the given path\n",
        "print(f\"There are {len(os.listdir(source_path_dogs))} dog images.\")\n",
        "print(f\"There are {len(os.listdir(source_path_cats))} cat images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F-QkLjxpmyK2",
      "metadata": {
        "cellView": "code",
        "id": "F-QkLjxpmyK2",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# Define root directory\n",
        "root_dir = '/tmp/cats-v-dogs'\n",
        "\n",
        "# Empty directory to prevent FileExistsError is the function is run several times\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "def create_train_val_dirs(root_path):\n",
        "  \"\"\"\n",
        "  Creates directories for the train and test sets\n",
        "  \n",
        "  Args:\n",
        "    root_path (string) - the base directory path to create subdirectories from\n",
        "  \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"  \n",
        "\n",
        "\n",
        "  train_dir = os.path.join(root_path, 'training')\n",
        "  validation_dir = os.path.join(root_path, 'validation')\n",
        "\n",
        "  # Directory containing training cat/dog pictures\n",
        "  train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "  train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "  # Directory containing validation cat/dog pictures\n",
        "  validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "  validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "  # Create subdirectories\n",
        "  os.makedirs(train_cats_dir)\n",
        "  os.makedirs(train_dogs_dir)\n",
        "  os.makedirs(validation_cats_dir)\n",
        "  os.makedirs(validation_dogs_dir)\n",
        "  \n",
        "  \n",
        "try:\n",
        "  create_train_val_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"root directory does not work\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dhtL344OK00",
      "metadata": {
        "id": "5dhtL344OK00",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# Testing if sub-directories are created properly\n",
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zvSODo0f9LaU",
      "metadata": {
        "cellView": "code",
        "id": "zvSODo0f9LaU",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test sets with given ratio\n",
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "\n",
        "  \"\"\"\n",
        "  Splits the data into train and test sets\n",
        "  \n",
        "  Args:\n",
        "    SOURCE_DIR (string): directory path containing the images\n",
        "    TRAINING_DIR (string): directory path to be used for training\n",
        "    VALIDATION_DIR (string): directory path to be used for validation\n",
        "    SPLIT_SIZE (float): proportion of the dataset to be used for training\n",
        "    \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  data = random.sample(os.listdir(SOURCE_DIR), len(os.listdir(SOURCE_DIR)))\n",
        "  for i in range(int(SPLIT_SIZE*len(data))):\n",
        "    file_path = os.path.join(SOURCE_DIR, data[i])\n",
        "    destination = os.path.join(TRAINING_DIR, data[i])\n",
        "    if os.path.getsize(file_path) == 0:\n",
        "      print(f'{data[i]} is zero length, so ignoring.')\n",
        "    else:\n",
        "      copyfile(file_path, destination)\n",
        "\n",
        "  for i in range(int(SPLIT_SIZE*len(data)), len(data)):\n",
        "    file_path = os.path.join(SOURCE_DIR, data[i])\n",
        "    destination = os.path.join(VALIDATION_DIR, data[i])\n",
        "    if os.path.getsize(file_path) == 0:\n",
        "      print(f'{data[i]} is zero length, so ignoring.')\n",
        "    else:\n",
        "      copyfile(file_path, destination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FlIdoUeX9S-9",
      "metadata": {
        "id": "FlIdoUeX9S-9",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define paths\n",
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "\n",
        "TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n",
        "VALIDATION_DIR = \"/tmp/cats-v-dogs/validation/\"\n",
        "\n",
        "TRAINING_CATS_DIR = os.path.join(TRAINING_DIR, \"cats/\")\n",
        "VALIDATION_CATS_DIR = os.path.join(VALIDATION_DIR, \"cats/\")\n",
        "\n",
        "TRAINING_DOGS_DIR = os.path.join(TRAINING_DIR, \"dogs/\")\n",
        "VALIDATION_DOGS_DIR = os.path.join(VALIDATION_DIR, \"dogs/\")\n",
        "\n",
        "# Empty directories if the data was previously split\n",
        "if len(os.listdir(TRAINING_CATS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_CATS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_DOGS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_DOGS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_CATS_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_CATS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_DOGS_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_DOGS_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "# Define proportion of images used for training\n",
        "split_size = .9\n",
        "\n",
        "# Split the data\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, VALIDATION_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, VALIDATION_DOGS_DIR, split_size)\n",
        "\n",
        "# Check the number of images in train and test sets\n",
        "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_CATS_DIR))} images of cats for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_DOGS_DIR))} images of dogs for training\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_CATS_DIR))} images of cats for validation\")\n",
        "\n",
        "# Check whether the function makes copies rather than moving the images\n",
        "print(f\"\\n\\nOriginal cat directory has {len(os.listdir(CAT_SOURCE_DIR))} images\")\n",
        "print(f\"Original dog directory has {len(os.listdir(DOG_SOURCE_DIR))} images\\n\")\n",
        "\n",
        "# Training and validation split results\n",
        "print(f\"There are {len(os.listdir(TRAINING_CATS_DIR))} images of cats for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_DOGS_DIR))} images of dogs for training\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_CATS_DIR))} images of cats for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_DOGS_DIR))} images of dogs for validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9b3309c",
      "metadata": {
        "id": "b9b3309c"
      },
      "source": [
        "### Data generator from directory with augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fQrZfVgz4j2g",
      "metadata": {
        "cellView": "code",
        "id": "fQrZfVgz4j2g",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  \"\"\"\n",
        "  Creates the training and validation data generators\n",
        "  \n",
        "  Args:\n",
        "    TRAINING_DIR (string): directory path containing the training images\n",
        "    VALIDATION_DIR (string): directory path containing the testing/validation images\n",
        "    \n",
        "  Returns:\n",
        "    train_generator, validation_generator - tuple containing the generators\n",
        "  \"\"\"\n",
        "\n",
        "  # Instantiate\n",
        "  train_datagen = ImageDataGenerator(rescale=1./255.,\n",
        "                                     rotation_range=30,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     shear_range=0.3,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode='nearest')\n",
        "\n",
        "  # pass dir, batch size, mode, and target size\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=32,\n",
        "                                                      class_mode='binary',\n",
        "                                                      target_size=(150, 150))\n",
        "\n",
        "  # Validation set does not require augmentation\n",
        "  validation_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "  # pass dir, batch size, mode, and target size\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=32,\n",
        "                                                                class_mode='binary',\n",
        "                                                                target_size=(150, 150))\n",
        "  return train_generator, validation_generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qM7FxrjGiobD",
      "metadata": {
        "id": "qM7FxrjGiobD",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# Test generators\n",
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a53731f",
      "metadata": {
        "id": "8a53731f"
      },
      "source": [
        "### Create and train a simple model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oDPK8tUB_O9e",
      "metadata": {
        "cellView": "code",
        "id": "oDPK8tUB_O9e",
        "lines_to_next_cell": 2,
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  ### Using Keras APIs from TF\n",
        "\n",
        "  model = tf.keras.models.Sequential([ \n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='swish', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='swish'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='swish'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='swish'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation='swish'),\n",
        "    tf.keras.layers.Dense(1024, activation='swish'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),  # sigmoid for binary classification\n",
        "  ])\n",
        "\n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy']) \n",
        "    \n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5qE1G6JB4fMn",
      "metadata": {
        "id": "5qE1G6JB4fMn",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get the untrained model\n",
        "model = create_model()\n",
        "\n",
        "# Train the model\n",
        "# Stored in the history object so information about training can be later retrieved\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05983cce",
      "metadata": {
        "id": "05983cce"
      },
      "source": [
        "## Plotting training results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MWZrJN4-65RC",
      "metadata": {
        "id": "MWZrJN4-65RC",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "397224b3cdb3a23561542feed94c5cf45952f2aadda9fa59ec57fed9311c625f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}